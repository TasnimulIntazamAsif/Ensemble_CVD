# ğŸ«€ Cardiovascular Disease Risk Prediction

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Accuracy](https://img.shields.io/badge/Accuracy-91.33%25-brightgreen.svg)](PERFORMANCE_SUMMARY.md)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-success.svg)](PERFORMANCE_SUMMARY.md)

> **Advanced Machine Learning Model for Cardiovascular Disease Risk Assessment**  
> **Achieved 91.33% Accuracy** - A **21.33% improvement** over baseline models

## ğŸ“‹ Table of Contents

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸš€ Key Features](#-key-features)
- [ğŸ“Š Dataset Information](#-dataset-information)
- [ğŸ—ï¸ Architecture & Models](#ï¸-architecture--models)
- [ğŸ“ˆ Performance Results](#-performance-results)
- [ğŸ› ï¸ Installation & Setup](#ï¸-installation--setup)
- [ğŸ’» Usage Examples](#-usage-examples)
- [ğŸ”¬ Technical Details](#-technical-details)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## ğŸ¯ Project Overview

This project implements a **state-of-the-art machine learning system** for predicting cardiovascular disease (CVD) risk levels based on patient health parameters. The model has been **significantly enhanced** from a baseline accuracy of ~70% to an **exceptional 91.33% accuracy**, making it suitable for clinical decision support and preventive healthcare applications.

### ğŸ¯ **Primary Objectives**
- **Predict CVD Risk Levels**: LOW, INTERMEDIATE, HIGH
- **Achieve >85% Accuracy**: Successfully exceeded with 91.33%
- **Provide Medical Insights**: Feature importance analysis for healthcare professionals
- **Enable Early Intervention**: Identify high-risk patients for preventive measures

### ğŸ¥ **Medical Applications**
- **Primary Care**: Routine health check-ups and risk assessment
- **Preventive Medicine**: Early identification of cardiovascular risk factors
- **Clinical Decision Support**: Assist healthcare providers in treatment planning
- **Population Health**: Large-scale screening and risk stratification

## ğŸš€ Key Features

### ğŸ”¬ **Advanced Feature Engineering**
- **Age Groups**: Young (0-30), Adult (31-45), Middle (46-60), Senior (60+)
- **BMI Categories**: Underweight, Normal, Overweight, Obese
- **Medical Ratios**: BP Ratio, Cholesterol Ratio, Waist-to-Height Ratio
- **Metabolic Indices**: BMI Ã— Fasting Blood Sugar, Cardiovascular Index
- **Interaction Features**: AgeÃ—BMI, BPÃ—Cholesterol, AgeÃ—Blood Pressure

### ğŸ§  **Machine Learning Models**
- **XGBoost**: Primary model with hyperparameter optimization
- **Random Forest**: Enhanced with feature importance analysis
- **Gradient Boosting**: Advanced boosting algorithm
- **Ensemble Methods**: Voting and Bagging classifiers
- **Support Vector Machines**: For complex pattern recognition
- **Neural Networks**: Deep learning capabilities

### ğŸ“Š **Data Processing Pipeline**
- **Robust Scaling**: Outlier-resistant data normalization
- **Advanced Imputation**: Domain-aware missing value handling
- **Feature Selection**: Statistical and information-theoretic methods
- **Data Balancing**: SMOTEENN for handling class imbalance
- **Cross-Validation**: 5-fold stratified validation

## ğŸ“Š Dataset Information

### ğŸ“ˆ **Dataset Overview**
- **Size**: 3,021 patient records
- **Features**: 22 health parameters
- **Target**: CVD Risk Level (3 classes)
- **Source**: Bangladesh Cardiovascular Health Study
- **Quality**: Clinical-grade medical data

### ğŸ¥ **Health Parameters Included**

| Category | Parameters |
|----------|------------|
| **Demographics** | Age, Sex, Weight, Height, BMI |
| **Cardiovascular** | Systolic BP, Diastolic BP, Blood Pressure Category |
| **Metabolic** | Total Cholesterol, HDL, LDL, Fasting Blood Sugar |
| **Lifestyle** | Smoking Status, Physical Activity Level |
| **Medical History** | Diabetes Status, Family History of CVD |
| **Body Composition** | Abdominal Circumference, Waist-to-Height Ratio |

### ğŸ¯ **Target Variable Distribution**
- **LOW Risk**: ~33% of patients
- **INTERMEDIATE Risk**: ~45% of patients  
- **HIGH Risk**: ~22% of patients

## ğŸ—ï¸ Architecture & Models

### ğŸ”§ **Model Pipeline Architecture**

```
Raw Data â†’ Feature Engineering â†’ Preprocessing â†’ Feature Selection â†’ 
Model Training â†’ Hyperparameter Tuning â†’ Ensemble Creation â†’ Validation
```

### ğŸ¯ **Primary Models**

#### **1. XGBoost (Best Performer)**
- **Accuracy**: 91.33%
- **Algorithm**: Extreme Gradient Boosting
- **Optimization**: Grid Search with Cross-Validation
- **Features**: 21 selected features
- **Status**: âœ… Production Ready

#### **2. Random Forest**
- **Accuracy**: 85.33%
- **Algorithm**: Ensemble of Decision Trees
- **Features**: Feature importance analysis
- **Use Case**: Interpretability and feature ranking

#### **3. Gradient Boosting**
- **Accuracy**: 90.67%
- **Algorithm**: Sequential boosting
- **Learning Rate**: 0.1
- **Estimators**: 200

#### **4. Ensemble Methods**
- **Voting Classifier**: 90.00%
- **Bagging Classifier**: Available
- **Strategy**: Combine best performing models

### ğŸ§® **Feature Selection Strategy**
- **F-Test Selection**: Statistical significance testing
- **Mutual Information**: Information-theoretic selection
- **Hybrid Approach**: Combining multiple methods
- **Feature Ranking**: Based on multiple criteria

## ğŸ“ˆ Performance Results

### ğŸ† **Model Performance Comparison**

| Model | Accuracy | Precision | Recall | F1-Score | Status |
|-------|----------|-----------|--------|----------|---------|
| **XGBoost** | **91.33%** | **90.45%** | **91.33%** | **90.88%** | ğŸ¥‡ Best |
| **Gradient Boosting** | 90.67% | 89.78% | 90.67% | 90.22% | ğŸ¥ˆ Runner-up |
| **Voting Classifier** | 90.00% | 89.12% | 90.00% | 89.56% | ğŸ¥‰ Ensemble |
| **Random Forest** | 85.33% | 84.56% | 85.33% | 84.94% | Reliable |

### ğŸ“Š **Performance Improvement Summary**

| Metric | Baseline | Enhanced | Improvement |
|--------|----------|----------|-------------|
| **Overall Accuracy** | 70% | **91.33%** | **+21.33%** |
| **XGBoost Performance** | 70% | **91.33%** | **+21.33%** |
| **Random Forest Performance** | 69% | **85.33%** | **+16.33%** |
| **Model Robustness** | Low | **High** | **Significant** |

### ğŸ” **Feature Importance Analysis**

**Top 10 Most Important Features:**
1. **CVD Risk Score** (F-Score: 62.02)
2. **Cholesterol_Ratio** (F-Score: 45.67)
3. **Smoking Status** (F-Score: 36.20)
4. **Estimated LDL** (F-Score: 35.84)
5. **Diabetes Status** (F-Score: 32.42)
6. **Family History of CVD** (F-Score: 31.18)
7. **BMI** (F-Score: 28.01)
8. **HDL** (F-Score: 24.36)
9. **Age_BMI_Interaction** (F-Score: 24.21)
10. **Total Cholesterol** (F-Score: 22.05)

## ğŸ› ï¸ Installation & Setup

### ğŸ“‹ **Prerequisites**
- Python 3.8 or higher
- pip package manager
- Git (for cloning)

### ğŸ”§ **Installation Steps**

#### **1. Clone the Repository**
```bash
git clone https://github.com/yourusername/CardioVascular_Disease_Risk_Prediction.git
cd CardioVascular_Disease_Risk_Prediction
```

#### **2. Create Virtual Environment (Recommended)**
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# macOS/Linux
python3 -m venv .venv
source .venv/bin/activate
```

#### **3. Install Dependencies**
```bash
pip install -r requirements.txt
```

#### **4. Verify Installation**
```bash
python -c "import pandas, numpy, sklearn, xgboost; print('All packages installed successfully!')"
```

### ğŸ“¦ **Required Packages**
```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
xgboost>=1.5.0
matplotlib>=3.5.0
seaborn>=0.11.0
imbalanced-learn>=0.8.0
joblib>=1.1.0
```

## ğŸ’» Usage Examples

### ğŸš€ **Quick Start**

#### **1. Run the Complete Pipeline**
```bash
python CVD_ASIF_Enhanced.py
```

#### **2. Jupyter Notebook (Interactive)**
```bash
jupyter notebook CVD_ASIF_Enhanced.ipynb
```

#### **3. Load Pre-trained Models**
```python
import joblib
import pickle

# Load the best model
model = joblib.load('xgb_enhanced_model.joblib')

# Load preprocessor
preprocessor = joblib.load('enhanced_preprocessor.joblib')

# Load selected features
features = pickle.load(open('selected_features.pkl', 'rb'))

# Load target encoder
encoder = joblib.load('target_encoder.joblib')
```

### ğŸ”® **Make Predictions**

#### **Single Patient Prediction**
```python
def predict_cvd_risk(patient_data, model, preprocessor, features, encoder):
    """
    Predict CVD risk for a single patient
    
    Args:
        patient_data (dict): Patient health parameters
        model: Trained ML model
        preprocessor: Data preprocessor
        features: Selected feature list
        encoder: Target label encoder
    
    Returns:
        str: Predicted risk level (LOW/INTERMEDIATE/HIGH)
    """
    import pandas as pd
    
    # Convert to DataFrame
    X_input = pd.DataFrame([patient_data])
    
    # Select features
    X_selected = X_input[features].copy()
    
    # Preprocess data
    X_scaled = preprocessor.transform(X_selected)
    
    # Make prediction
    prediction = model.predict(X_scaled)
    
    # Decode prediction
    risk_level = encoder.inverse_transform(prediction)[0]
    
    return risk_level

# Example usage
patient_data = {
    'Age': 45,
    'BMI': 28.5,
    'Systolic BP': 140,
    'Diastolic BP': 90,
    'Total Cholesterol (mg/dL)': 200,
    'HDL (mg/dL)': 50,
    'Fasting Blood Sugar (mg/dL)': 110,
    'Smoking Status': 'N',
    'Diabetes Status': 'N',
    'Physical Activity Level': 'Moderate',
    'Family History of CVD': 'N'
}

risk = predict_cvd_risk(patient_data, model, preprocessor, features, encoder)
print(f"Predicted CVD Risk: {risk}")
```

#### **Batch Prediction**
```python
def predict_batch(patients_df, model, preprocessor, features, encoder):
    """
    Predict CVD risk for multiple patients
    
    Args:
        patients_df (DataFrame): DataFrame with patient data
        model: Trained ML model
        preprocessor: Data preprocessor
        features: Selected feature list
        encoder: Target label encoder
    
    Returns:
        DataFrame: Original data with predictions
    """
    # Select features
    X_selected = patients_df[features].copy()
    
    # Preprocess data
    X_scaled = preprocessor.transform(X_selected)
    
    # Make predictions
    predictions = model.predict(X_scaled)
    
    # Decode predictions
    risk_levels = encoder.inverse_transform(predictions)
    
    # Add predictions to original DataFrame
    patients_df['Predicted_CVD_Risk'] = risk_levels
    
    return patients_df
```

### ğŸ“Š **Model Training & Evaluation**

#### **Train New Model**
```python
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Load and preprocess data
df = pd.read_csv('CVD_Dataset.csv')

# Feature engineering (see CVD_ASIF_Enhanced.py for full implementation)
# ... feature engineering code ...

# Split data
X = df.drop('CVD Risk Level', axis=1)
y = df['CVD Risk Level']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Train model
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
```

## ğŸ”¬ Technical Details

### ğŸ§® **Feature Engineering Details**

#### **Age Groups**
```python
df['Age_Group'] = pd.cut(df['Age'], 
    bins=[0, 30, 45, 60, 100], 
    labels=['Young', 'Adult', 'Middle', 'Senior'])
```

#### **BMI Categories**
```python
df['BMI_Category'] = pd.cut(df['BMI'], 
    bins=[0, 18.5, 25, 30, 100], 
    labels=['Underweight', 'Normal', 'Overweight', 'Obese'])
```

#### **Medical Ratios**
```python
df['BP_Ratio'] = df['Systolic BP'] / df['Diastolic BP']
df['Cholesterol_Ratio'] = df['Total Cholesterol (mg/dL)'] / df['HDL (mg/dL)']
```

#### **Metabolic Indices**
```python
df['Metabolic_Index'] = df['BMI'] * df['Fasting Blood Sugar (mg/dL)'] / 100
df['Cardiovascular_Index'] = (df['Systolic BP'] + df['Diastolic BP']) * df['Age'] / 100
```

### ğŸ” **Feature Selection Methods**

#### **F-Test Selection**
```python
from sklearn.feature_selection import SelectKBest, f_classif

f_selector = SelectKBest(score_func=f_classif, k='all')
f_scores = f_selector.fit(X, y)
top_features_f = X.columns[f_scores.get_support()].tolist()
```

#### **Mutual Information Selection**
```python
from sklearn.feature_selection import mutual_info_classif

mi_scores = mutual_info_classif(X, y)
top_features_mi = X.columns[mi_scores > np.mean(mi_scores)].tolist()
```

### âš–ï¸ **Data Balancing Strategy**

#### **SMOTEENN Implementation**
```python
from imblearn.combine import SMOTEENN

smoteenn = SMOTEENN(random_state=42)
X_balanced, y_balanced = smoteenn.fit_resample(X_selected, y_selected)
```

### ğŸ¯ **Hyperparameter Optimization**

#### **XGBoost Grid Search**
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 0.9, 1.0]
}

grid_search = GridSearchCV(
    XGBClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
```

## ğŸ“ Project Structure

```
CardioVascular_Disease_Risk_Prediction/
â”œâ”€â”€ ğŸ“Š Data/
â”‚   â”œâ”€â”€ CVD_Dataset.csv              # Main dataset (3,021 records)
â”‚   â””â”€â”€ selected_features.pkl        # Selected feature list
â”œâ”€â”€ ğŸ§  Models/
â”‚   â”œâ”€â”€ xgb_enhanced_model.joblib   # Best performing XGBoost model
â”‚   â”œâ”€â”€ rf_clf.pkl                  # Random Forest model
â”‚   â”œâ”€â”€ gb_enhanced_model.joblib    # Gradient Boosting model
â”‚   â”œâ”€â”€ enhanced_preprocessor.joblib # Data preprocessing pipeline
â”‚   â””â”€â”€ target_encoder.joblib       # Target variable encoder
â”œâ”€â”€ ğŸ“ Code/
â”‚   â”œâ”€â”€ CVD_ASIF_Enhanced.py        # Main Python script
â”‚   â”œâ”€â”€ CVD_ASIF_Enhanced.ipynb     # Jupyter notebook
â”‚   â”œâ”€â”€ XGBoost_Model_Code.py       # XGBoost specific implementation
â”‚   â””â”€â”€ search_specific.py          # Search functionality
â”œâ”€â”€ ğŸ“š Documentation/
â”‚   â”œâ”€â”€ README.md                   # This file
â”‚   â”œâ”€â”€ README_ENHANCED.md          # Enhanced documentation
â”‚   â”œâ”€â”€ PERFORMANCE_SUMMARY.md      # Performance results
â”‚   â””â”€â”€ NOTEBOOK_UPDATE_GUIDE.md    # Notebook usage guide
â”œâ”€â”€ ğŸ”§ Configuration/
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ .gitignore                  # Git ignore rules
â”‚   â””â”€â”€ LICENSE                     # MIT License
â””â”€â”€ ğŸ“ˆ Results/
    â””â”€â”€ models/                     # Additional model files
```

### ğŸ“‹ **File Descriptions**

- **`CVD_Dataset.csv`**: Primary dataset with 3,021 patient records
- **`CVD_ASIF_Enhanced.py`**: Main Python script with complete pipeline
- **`CVD_ASIF_Enhanced.ipynb`**: Interactive Jupyter notebook
- **`xgb_enhanced_model.joblib`**: Best performing model (91.33% accuracy)
- **`enhanced_preprocessor.joblib`**: Data preprocessing pipeline
- **`selected_features.pkl`**: List of 21 selected features
- **`target_encoder.joblib`**: Target variable encoding

## ğŸš€ Advanced Usage

### ğŸ”„ **Model Retraining**

#### **Incremental Learning**
```python
# Load existing model
model = joblib.load('xgb_enhanced_model.joblib')

# New data
new_data = pd.read_csv('new_patients.csv')

# Retrain with new data
model.fit(new_data[features], new_data['CVD Risk Level'])

# Save updated model
joblib.dump(model, 'xgb_enhanced_model_updated.joblib')
```

#### **Hyperparameter Tuning**
```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import uniform, randint

# Define parameter distributions
param_dist = {
    'n_estimators': randint(100, 500),
    'max_depth': randint(3, 10),
    'learning_rate': uniform(0.01, 0.3),
    'subsample': uniform(0.6, 0.4)
}

# Random search
random_search = RandomizedSearchCV(
    XGBClassifier(random_state=42),
    param_dist,
    n_iter=100,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

random_search.fit(X_train, y_train)
```

### ğŸ“Š **Performance Monitoring**

#### **Cross-Validation Analysis**
```python
from sklearn.model_selection import cross_val_score, StratifiedKFold

# 5-fold stratified cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Cross-validation scores
cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')

print(f"CV Scores: {cv_scores}")
print(f"Mean CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
```

#### **Feature Importance Tracking**
```python
# Get feature importance
importance = model.feature_importances_

# Create importance DataFrame
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': importance
}).sort_values('importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance.head(15), x='importance', y='feature')
plt.title('Top 15 Feature Importance')
plt.show()
```

## ğŸ”§ Troubleshooting

### âŒ **Common Issues & Solutions**

#### **1. Memory Errors**
```bash
# Reduce memory usage
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1

# Or use smaller feature set
python -c "import pickle; features = pickle.load(open('selected_features.pkl', 'rb')); print('Features:', len(features))"
```

#### **2. Package Installation Issues**
```bash
# Upgrade pip
python -m pip install --upgrade pip

# Install specific versions
pip install scikit-learn==1.0.2 xgboost==1.5.0

# Use conda if pip fails
conda install scikit-learn xgboost pandas numpy
```

#### **3. Model Loading Errors**
```python
# Check file paths
import os
print("Current directory:", os.getcwd())
print("Files in directory:", os.listdir('.'))

# Verify file integrity
import joblib
try:
    model = joblib.load('xgb_enhanced_model.joblib')
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")
```

### ğŸ“Š **Performance Optimization Tips**

1. **Feature Selection**: Use top 15-20 features for optimal performance
2. **Cross-validation**: 5-fold for optimal balance of speed and accuracy
3. **Ensemble Size**: 3-5 models for voting classifier
4. **Memory Management**: Process data in chunks for large datasets

## ğŸ¤ Contributing

We welcome contributions to improve this cardiovascular disease risk prediction model!

### ğŸ”„ **How to Contribute**

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** and add tests if applicable
4. **Commit your changes**: `git commit -m 'Add amazing feature'`
5. **Push to the branch**: `git push origin feature/amazing-feature`
6. **Open a Pull Request**

### ğŸ“‹ **Contribution Guidelines**

- **Code Style**: Follow PEP 8 Python style guide
- **Documentation**: Add docstrings and comments for new functions
- **Testing**: Include tests for new features
- **Medical Accuracy**: Ensure medical insights are clinically relevant
- **Performance**: Maintain or improve model accuracy

### ğŸ¯ **Areas for Improvement**

- **Additional Algorithms**: Deep learning models, transformers
- **Feature Engineering**: More medical domain features
- **Data Augmentation**: Synthetic data generation
- **API Development**: REST API for model deployment
- **Web Interface**: User-friendly prediction interface

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### ğŸ“œ **License Summary**
- **Commercial Use**: âœ… Allowed
- **Modification**: âœ… Allowed
- **Distribution**: âœ… Allowed
- **Private Use**: âœ… Allowed
- **Liability**: âŒ Limited
- **Warranty**: âŒ None

## ğŸ™ Acknowledgments

- **Medical Community**: For domain expertise and validation
- **Open Source Contributors**: For the excellent ML libraries
- **Research Community**: For cardiovascular health insights
- **Data Scientists**: For best practices and methodologies

## ğŸ“ Support & Contact

### ğŸ†˜ **Getting Help**

- **Documentation**: Check this README and other docs first
- **Issues**: Open a GitHub issue for bugs or feature requests
- **Discussions**: Use GitHub Discussions for questions
- **Email**: Contact project maintainers directly

### ğŸ”— **Useful Links**

- **Project Repository**: [GitHub](https://github.com/yourusername/CardioVascular_Disease_Risk_Prediction)
- **Dataset Source**: Bangladesh Cardiovascular Health Study
- **Medical Guidelines**: WHO Cardiovascular Risk Assessment
- **ML Resources**: Scikit-learn, XGBoost Documentation

---

## ğŸ‰ **Project Status: Production Ready!**

âœ… **Target Achieved**: >85% Accuracy  
ğŸ† **Best Performance**: 91.33% Accuracy  
ğŸš€ **Ready for**: Clinical Deployment  
ğŸ“Š **Validation**: 5-fold Cross-Validation  
ğŸ”¬ **Models**: Multiple ML Algorithms  

---

**â­ If this project helps you, please give it a star! â­**

*Built with â¤ï¸ for better cardiovascular health outcomes*
