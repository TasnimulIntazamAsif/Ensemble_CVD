# Ensemble CVD Risk Prediction Project

A comprehensive machine learning project for predicting Cardiovascular Disease (CVD) risk levels using ensemble methods and weighted feature fusion techniques.

## ğŸ“‹ Project Overview

This project implements advanced ensemble learning techniques to predict CVD risk levels (LOW, INTERMEDIARY, HIGH) using clinical and lifestyle features. The project explores both traditional ensemble methods and innovative weighted feature fusion approaches to improve prediction accuracy.

## ğŸ¯ Key Features

- **Multi-Model Ensemble**: Combines Random Forest, SVM, Bagging, and XGBoost classifiers
- **Weighted Feature Fusion**: Implements clinical and lifestyle feature weighting for optimal performance
- **Comprehensive Data Preprocessing**: Handles missing values, categorical encoding, and feature engineering
- **Advanced Visualization**: High-resolution plots for feature importance analysis
- **Cross-Validation**: Stratified K-Fold validation for robust model evaluation
- **Imbalanced Data Handling**: SMOTE and other techniques for class balance

## ğŸ“Š Dataset Information

- **Dataset**: CVD Dataset.csv
- **Size**: 3,019 samples with 22 features
- **Target Variable**: CVD Risk Level (LOW, INTERMEDIARY, HIGH)
- **Features**: 
  - Clinical: Age, BMI, Blood Pressure, Cholesterol levels, etc.
  - Lifestyle: Smoking status, Physical activity, Family history, etc.

### Dataset Structure
```
Shape: (3019, 22)
Target Distribution:
- LOW: ~32.9%
- INTERMEDIARY: ~34.4% 
- HIGH: ~32.7%
```

## ğŸ”§ Models Implemented

### Individual Models
1. **Random Forest Classifier** - 200 estimators, max_depth=20
2. **XGBoost Classifier** - 200 estimators, learning_rate=0.1
3. **Decision Tree Classifier** - max_depth=10
4. **K-Nearest Neighbors** - n_neighbors=7
5. **Support Vector Machine** - RBF kernel, C=1.0
6. **Naive Bayes** - Gaussian implementation
7. **Gradient Boosting** - 200 estimators, learning_rate=0.1

### Ensemble Methods
1. **Voting Classifier** (Soft Voting)
   - Combines: RF + SVM + Bagging + XGBoost
   - Achieves ~93.13% accuracy

2. **Weighted Feature Fusion**
   - Clinical features weight: 1.37
   - Lifestyle features weight: 1.58
   - Optimized through grid search

## ğŸ“ˆ Performance Results

### Cross-Validation Results (Stratified K-Fold)
| Model | Accuracy | F1-Score | Precision | Recall |
|-------|----------|----------|-----------|--------|
| Random Forest | 81.72% | 77.18% | 84.79% | 74.38% |
| XGBoost | 80.29% | 74.91% | 78.82% | 73.14% |
| Bagging DT | 78.11% | 73.98% | 79.86% | 71.67% |
| Decision Tree | 65.55% | 60.42% | 61.59% | 59.73% |
| KNN | 58.13% | 53.35% | 57.26% | 51.98% |
| SVM RBF | 51.41% | 36.11% | 33.72% | 39.40% |

### Ensemble Performance
- **4-Model Ensemble**: 93.13% accuracy
- **Best Individual Model**: XGBoost (93.89% accuracy)

## ğŸ› ï¸ Technical Implementation

### Data Preprocessing Pipeline
1. **Missing Value Handling**: Median imputation for numerical features
2. **Categorical Encoding**: 
   - One-hot encoding for nominal variables
   - Ordinal encoding for ordered categories
3. **Feature Scaling**: RobustScaler for outlier resistance
4. **Feature Engineering**: 
   - BMI categories
   - Blood pressure ratios
   - Metabolic indices

### Feature Groups
- **Clinical Features** (13 features): Age, BMI, Blood Pressure, Cholesterol, etc.
- **Lifestyle Features** (4 features): Physical Activity, Smoking, Diabetes, Family History

### Model Training Process
1. Train-test split (80-20) with stratification
2. Cross-validation with 5-fold StratifiedKFold
3. Hyperparameter optimization using GridSearchCV
4. Ensemble model training with soft voting

## ğŸ“ Project Structure

```
Ensemble_CVD/
â”œâ”€â”€ CVD Dataset.csv                           # Main dataset
â”œâ”€â”€ CVD_classifcation.ipynb                   # Basic classification notebook
â”œâ”€â”€ CVD_classifcation - weighter fusiion.ipynb # Advanced ensemble notebook
â”œâ”€â”€ enhanced_preprocessor.joblib              # Saved preprocessor
â”œâ”€â”€ models/                                   # Saved model directory
â”œâ”€â”€ LICENSE                                   # MIT License
â””â”€â”€ README.md                                 # This file
```

## ğŸš€ Getting Started

### Prerequisites
```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost imbalanced-learn joblib
```

### Optional Dependencies
```bash
pip install shap lime plotly  # For explainable AI features
```

### Running the Project
1. Clone the repository
2. Install required dependencies
3. Open either notebook:
   - `CVD_classifcation.ipynb` for basic implementation
   - `CVD_classifcation - weighter fusiion.ipynb` for advanced ensemble methods
4. Run all cells to reproduce results

## ğŸ” Key Findings

### Feature Importance Analysis
- **Family History of CVD**: Most important lifestyle factor
- **Fasting Blood Sugar**: Key clinical indicator
- **Estimated LDL**: Significant cholesterol marker
- **Smoking Status**: Important behavioral factor

### Model Insights
- **Random Forest** shows best balance of performance and interpretability
- **XGBoost** achieves highest individual accuracy
- **Ensemble methods** provide robust predictions with reduced variance
- **Weighted fusion** improves performance by emphasizing important feature groups

## ğŸ“Š Visualization Features

- High-resolution feature importance plots
- Correlation matrix heatmaps
- Confusion matrix visualizations
- Model performance comparisons
- Cross-validation result summaries

## ğŸ”¬ Research Applications

This project demonstrates:
- Advanced ensemble learning techniques
- Feature fusion methodologies
- Medical data preprocessing best practices
- Model interpretability in healthcare
- Cross-validation strategies for imbalanced data

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Tasnimul Intazam Asif**
- Copyright (c) 2025

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ Contact

For questions or suggestions, please open an issue in the repository.

---

*This project showcases advanced machine learning techniques applied to cardiovascular disease risk prediction, combining traditional ensemble methods with innovative feature fusion approaches.*
